# Wolo å†å²å‹ç¼©åŠŸèƒ½ä¼˜åŒ–è®¡åˆ’

## æ‰§è¡Œæ‘˜è¦

æœ¬è®¡åˆ’æ—¨åœ¨å°† wolo çš„å†å²å‹ç¼©åŠŸèƒ½å‘ opencode çš„å®ç°å¯¹é½ï¼Œä¼˜å…ˆå®ç°**æœ€å®¹æ˜“å®ç°ä¸”æ•ˆæœæœ€æ˜¾è‘—**çš„æ”¹è¿›ã€‚è®¡åˆ’åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œä»æœ€ç´§æ€¥çš„é—®é¢˜ä¿®å¤åˆ°é«˜çº§åŠŸèƒ½å¢å¼ºã€‚

---

## ä¸€ã€ç°çŠ¶åˆ†æ

### 1.1 å½“å‰å®ç°çš„å…³é”®é—®é¢˜

æ ¹æ®å¯¹æ¯”åˆ†æï¼Œwolo çš„å‹ç¼©å®ç°å­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

1. **âŒ å†å²ä¸¢å¤±ï¼ˆæœ€ä¸¥é‡ï¼‰**
   - å‹ç¼©ååŸå§‹æ¶ˆæ¯è¢«æ›¿æ¢ï¼Œæ— æ³•æ¢å¤
   - ç¼ºå°‘å®¡è®¡è¿½è¸ªèƒ½åŠ›
   - æ— æ³•è°ƒè¯•å‹ç¼©é—®é¢˜

2. **âŒ é…ç½®ç¡¬ç¼–ç **
   - `recent_exchanges = 6` å›ºå®šå€¼
   - `RESERVED_TOKENS = 2000` å›ºå®šå€¼
   - æ£€æŸ¥é—´éš” `step % 5 == 0` å›ºå®šå€¼
   - æ— æ³•æ ¹æ®åœºæ™¯è°ƒæ•´

3. **âŒ Token ä¼°ç®—ä¸å‡†ç¡®**
   - å­—ç¬¦ä¼°ç®—ï¼ˆ4å­—ç¬¦=1tokenï¼‰è¯¯å·®å¤§
   - ä¸åŒºåˆ†ä»£ç ã€è‹±æ–‡ã€ä¸­æ–‡çš„tokenå¯†åº¦
   - å¯èƒ½å¯¼è‡´è¿‡æ—©æˆ–è¿‡æ™šå‹ç¼©

4. **âŒ æ‘˜è¦è´¨é‡å—é™**
   - 500å­—ç¬¦ç¡¬é™åˆ¶å¯èƒ½æˆªæ–­é‡è¦ä¿¡æ¯
   - Prompt è¿‡äºç®€å•
   - æ— ç»“æ„åŒ–è¾“å‡º

5. **âŒ è§¦å‘æœºåˆ¶ä¸ç²¾ç¡®**
   - æ¯5æ­¥æ‰æ£€æŸ¥ä¸€æ¬¡ï¼Œå¯èƒ½é”™è¿‡æº¢å‡º
   - åŸºäºä¼°ç®—è€Œéå®é™…tokenä½¿ç”¨
   - æ— æ‰‹åŠ¨è§¦å‘æœºåˆ¶

### 1.2 å½“å‰æ¶æ„ä¼˜åŠ¿

âœ… **æ¶ˆæ¯æŒä¹…åŒ–å®Œå–„**
- æ¯ä¸ªæ¶ˆæ¯å•ç‹¬æ–‡ä»¶å­˜å‚¨
- æ”¯æŒåŸå­å†™å…¥å’Œæ–‡ä»¶é”
- å·²æœ‰å®Œæ•´çš„åºåˆ—åŒ–/ååºåˆ—åŒ–æœºåˆ¶

âœ… **ä»£ç ç»“æ„æ¸…æ™°**
- `compaction.py` æ¨¡å—åŒ–è‰¯å¥½
- `session.py` å­˜å‚¨å±‚å®Œå–„
- `agent.py` é›†æˆç‚¹æ˜ç¡®

âœ… **é”™è¯¯å¤„ç†åŸºç¡€**
- å·²æœ‰ try-catch å›é€€æœºåˆ¶
- æ—¥å¿—è®°å½•å®Œå–„

---

## äºŒã€ä¼˜åŒ–ç­–ç•¥ä¸ä¼˜å…ˆçº§

### 2.1 ä¼˜å…ˆçº§è¯„ä¼°çŸ©é˜µ

| æ”¹è¿›é¡¹ | å®ç°éš¾åº¦ | æ•ˆæœå½±å“ | ä¼˜å…ˆçº§ | é¢„è®¡å·¥ä½œé‡ |
|--------|---------|---------|--------|-----------|
| **ä¿å­˜å‹ç¼©å†å²** | ä½ | æé«˜ | ğŸ”´ P0 | 2-3å°æ—¶ |
| **é…ç½®åŒ–å‚æ•°** | ä½ | é«˜ | ğŸ”´ P0 | 1-2å°æ—¶ |
| **æ”¹è¿›æ‘˜è¦è´¨é‡** | ä½ | é«˜ | ğŸŸ¡ P1 | 1-2å°æ—¶ |
| **æ”¹è¿›è§¦å‘æœºåˆ¶** | ä¸­ | é«˜ | ğŸŸ¡ P1 | 3-4å°æ—¶ |
| **Tokenä¼°ç®—æ”¹è¿›** | ä¸­ | ä¸­ | ğŸŸ¢ P2 | 4-6å°æ—¶ |
| **å·¥å…·è¾“å‡ºä¿®å‰ª** | é«˜ | ä¸­ | ğŸŸ¢ P2 | 6-8å°æ—¶ |
| **æ‰‹åŠ¨è§¦å‘** | ä½ | ä¸­ | ğŸŸ¢ P2 | 1-2å°æ—¶ |

### 2.2 åˆ†é˜¶æ®µå®æ–½ç­–ç•¥

**é˜¶æ®µä¸€ï¼ˆP0 - ç«‹å³å®æ–½ï¼‰**ï¼šä¿®å¤å…³é”®é—®é¢˜ï¼Œæœ€å°åŒ–æ”¹åŠ¨
- ä¿å­˜å‹ç¼©å†å²
- é…ç½®åŒ–å‚æ•°
- æ”¹è¿›æ‘˜è¦è´¨é‡

**é˜¶æ®µäºŒï¼ˆP1 - çŸ­æœŸä¼˜åŒ–ï¼‰**ï¼šæå‡ç²¾ç¡®åº¦å’Œç”¨æˆ·ä½“éªŒ
- æ”¹è¿›è§¦å‘æœºåˆ¶
- Tokenä¼°ç®—æ”¹è¿›

**é˜¶æ®µä¸‰ï¼ˆP2 - é•¿æœŸå¢å¼ºï¼‰**ï¼šé«˜çº§åŠŸèƒ½å’Œå®Œæ•´å¯¹é½
- å·¥å…·è¾“å‡ºä¿®å‰ª
- æ‰‹åŠ¨è§¦å‘
- äº‹ä»¶ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰

---

## ä¸‰ã€è¯¦ç»†å®æ–½è®¡åˆ’

## é˜¶æ®µä¸€ï¼šå…³é”®é—®é¢˜ä¿®å¤ï¼ˆP0ï¼‰

### ä»»åŠ¡ 1.1ï¼šä¿å­˜å‹ç¼©å†å² â­â­â­

**ç›®æ ‡**ï¼šä¿ç•™åŸå§‹æ¶ˆæ¯ï¼Œæ·»åŠ å‹ç¼©å…ƒæ•°æ®

**å®ç°æ–¹æ¡ˆ**ï¼š

#### æ–¹æ¡ˆAï¼šåœ¨æ¶ˆæ¯ä¸­æ·»åŠ å‹ç¼©æ ‡è®°ï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹**ï¼š
- æœ€å°æ”¹åŠ¨
- åˆ©ç”¨ç°æœ‰å­˜å‚¨æœºåˆ¶
- æ— éœ€é¢å¤–å­˜å‚¨ç©ºé—´

**å®ç°æ­¥éª¤**ï¼š

1. **æ‰©å±• Message ç±»**ï¼ˆ`session.py`ï¼‰ï¼š
```python
@dataclass
class Message:
    id: str
    role: str
    parts: list[Part]
    timestamp: float
    finished: bool = False
    finish_reason: str = ""
    reasoning_content: str = ""
    # æ–°å¢å­—æ®µ
    metadata: dict = field(default_factory=dict)  # å­˜å‚¨å‹ç¼©ä¿¡æ¯
```

2. **ä¿®æ”¹ `compact_messages` å‡½æ•°**ï¼ˆ`compaction.py`ï¼‰ï¼š
```python
async def compact_messages(
    messages: list[Message],
    config: Config,
    max_tokens: int | None = None,
    session_id: str | None = None  # æ–°å¢å‚æ•°
) -> list[Message]:
    # ... ç°æœ‰é€»è¾‘ ...
    
    # åˆ›å»ºå‹ç¼©æ‘˜è¦æ¶ˆæ¯
    summary_msg = Message(role="user")
    summary_msg.parts.append(TextPart(
        text=f"[Previous conversation summary: {summary}]"
    ))
    
    # æ·»åŠ å‹ç¼©å…ƒæ•°æ®
    summary_msg.metadata = {
        "compaction": True,
        "compacted_at": time.time(),
        "original_message_count": len(messages),
        "preserved_message_count": len(recent_messages),
        "compacted_message_ids": [msg.id for msg in to_summarize],
        "preserved_message_ids": [msg.id for msg in recent_messages]
    }
    
    compacted.append(summary_msg)
    compacted.extend(recent_messages)
    
    # æ ‡è®°è¢«å‹ç¼©çš„æ¶ˆæ¯ï¼ˆä¸åˆ é™¤ï¼Œåªæ ‡è®°ï¼‰
    if session_id:
        storage = get_storage()
        for msg in to_summarize:
            if not msg.metadata.get("compacted"):
                msg.metadata["compacted"] = True
                msg.metadata["compacted_at"] = time.time()
                msg.metadata["compaction_summary_id"] = summary_msg.id
                storage.save_message(session_id, msg)  # æ›´æ–°æ¶ˆæ¯å…ƒæ•°æ®
    
    return compacted
```

3. **ä¿®æ”¹è°ƒç”¨ç‚¹**ï¼ˆ`agent.py`ï¼‰ï¼š
```python
# åœ¨ _call_llm ä¸­ä¼ é€’ session_id
messages_to_use = await compact_messages(
    messages, config, limit, session_id=session_id
)
```

4. **æ·»åŠ æŸ¥è¯¢å‡½æ•°**ï¼ˆ`session.py`ï¼‰ï¼š
```python
def get_compaction_history(session_id: str) -> list[dict]:
    """è·å–å‹ç¼©å†å²è®°å½•"""
    messages = get_session_messages(session_id)
    compactions = []
    for msg in messages:
        if msg.metadata.get("compaction"):
            compactions.append({
                "summary_message_id": msg.id,
                "compacted_at": msg.metadata.get("compacted_at"),
                "original_count": msg.metadata.get("original_message_count"),
                "preserved_count": msg.metadata.get("preserved_message_count"),
                "compacted_ids": msg.metadata.get("compacted_message_ids", []),
            })
    return compactions

def get_original_messages(session_id: str, summary_message_id: str) -> list[Message]:
    """æ ¹æ®å‹ç¼©æ‘˜è¦æ¶ˆæ¯IDè·å–åŸå§‹æ¶ˆæ¯"""
    summary_msg = get_message(session_id, summary_message_id)
    if not summary_msg or not summary_msg.metadata.get("compaction"):
        return []
    
    compacted_ids = summary_msg.metadata.get("compacted_message_ids", [])
    all_messages = get_session_messages(session_id)
    return [msg for msg in all_messages if msg.id in compacted_ids]
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- å‹ç¼©ååŸå§‹æ¶ˆæ¯ä»ç„¶å­˜åœ¨
- å…ƒæ•°æ®æ­£ç¡®ä¿å­˜
- å¯ä»¥æŸ¥è¯¢å‹ç¼©å†å²
- å¯ä»¥æ¢å¤åŸå§‹æ¶ˆæ¯

**é¢„è®¡å·¥ä½œé‡**ï¼š2-3å°æ—¶

---

### ä»»åŠ¡ 1.2ï¼šé…ç½®åŒ–å‚æ•° â­â­

**ç›®æ ‡**ï¼šå°†ç¡¬ç¼–ç å€¼æ”¹ä¸ºå¯é…ç½®å‚æ•°

**å®ç°æ­¥éª¤**ï¼š

1. **æ‰©å±• Config ç±»**ï¼ˆ`config.py`ï¼‰ï¼š
```python
@dataclass
class CompactionConfig:
    """å‹ç¼©é…ç½®"""
    enabled: bool = True
    check_interval: int = 5  # æ¯Næ­¥æ£€æŸ¥ä¸€æ¬¡
    recent_exchanges: int = 6  # ä¿ç•™æœ€è¿‘Nè½®å¯¹è¯
    reserved_tokens: int = 2000  # ä¿ç•™çš„tokenæ•°
    summary_max_length: int | None = None  # Noneè¡¨ç¤ºä¸é™åˆ¶
    auto_compact: bool = True  # æ˜¯å¦è‡ªåŠ¨å‹ç¼©

@dataclass
class Config:
    # ... ç°æœ‰å­—æ®µ ...
    compaction: CompactionConfig = field(default_factory=CompactionConfig)
```

2. **ä»é…ç½®æ–‡ä»¶åŠ è½½**ï¼ˆ`config.py`ï¼‰ï¼š
```python
@classmethod
def from_env(cls, ...) -> "Config":
    # ... ç°æœ‰é€»è¾‘ ...
    
    # åŠ è½½å‹ç¼©é…ç½®
    compaction_data = config_data.get("compaction", {})
    compaction_config = CompactionConfig(
        enabled=compaction_data.get("enabled", True),
        check_interval=compaction_data.get("check_interval", 5),
        recent_exchanges=compaction_data.get("recent_exchanges", 6),
        reserved_tokens=compaction_data.get("reserved_tokens", 2000),
        summary_max_length=compaction_data.get("summary_max_length"),
        auto_compact=compaction_data.get("auto_compact", True),
    )
    
    return cls(
        # ... ç°æœ‰å‚æ•° ...
        compaction=compaction_config,
    )
```

3. **æ›´æ–° `compaction.py`**ï¼š
```python
# ç§»é™¤ç¡¬ç¼–ç å¸¸é‡
# recent_exchanges = 6  # åˆ é™¤
# RESERVED_TOKENS = 2000  # åˆ é™¤

async def compact_messages(
    messages: list[Message],
    config: Config,
    max_tokens: int | None = None,
    session_id: str | None = None
) -> list[Message]:
    # ä½¿ç”¨é…ç½®å€¼
    if max_tokens is None:
        max_tokens = config.max_tokens - config.compaction.reserved_tokens
    
    # ... å…¶ä»–é€»è¾‘ ...
    
    recent_exchanges = config.compaction.recent_exchanges
    # ... ä½¿ç”¨ recent_exchanges ...
```

4. **æ›´æ–° `agent.py`**ï¼š
```python
async def _call_llm(...):
    # æ£€æŸ¥å‹ç¼©é…ç½®
    if not config.compaction.enabled or not config.compaction.auto_compact:
        messages_to_use = messages
    elif step > 0 and step % config.compaction.check_interval == 0:
        # ... å‹ç¼©é€»è¾‘ ...
```

5. **é…ç½®æ–‡ä»¶ç¤ºä¾‹**ï¼ˆ`~/.wolo/config.yaml`ï¼‰ï¼š
```yaml
compaction:
  enabled: true
  check_interval: 3  # æ¯3æ­¥æ£€æŸ¥ä¸€æ¬¡ï¼ˆæ›´é¢‘ç¹ï¼‰
  recent_exchanges: 8  # ä¿ç•™8è½®å¯¹è¯
  reserved_tokens: 3000  # ä¿ç•™æ›´å¤štoken
  summary_max_length: null  # ä¸é™åˆ¶æ‘˜è¦é•¿åº¦
  auto_compact: true
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- é…ç½®æ­£ç¡®åŠ è½½
- é»˜è®¤å€¼ç”Ÿæ•ˆ
- é…ç½®æ–‡ä»¶è¦†ç›–é»˜è®¤å€¼
- ç¦ç”¨å‹ç¼©æ—¶æ­£å¸¸å·¥ä½œ

**é¢„è®¡å·¥ä½œé‡**ï¼š1-2å°æ—¶

---

### ä»»åŠ¡ 1.3ï¼šæ”¹è¿›æ‘˜è¦è´¨é‡ â­â­

**ç›®æ ‡**ï¼šæå‡æ‘˜è¦è´¨é‡ï¼Œç§»é™¤ç¡¬é™åˆ¶

**å®ç°æ­¥éª¤**ï¼š

1. **æ”¹è¿› Prompt**ï¼ˆ`compaction.py`ï¼‰ï¼š
```python
async def _summarize_messages(messages: list[Message], config: Config) -> str:
    # ... æå–å¯¹è¯æ–‡æœ¬ ...
    
    # æ”¹è¿›çš„promptï¼ˆå‚è€ƒopencodeï¼‰
    prompt_text = (
        "è¯·è¯¦ç»†æ€»ç»“ä»¥ä¸‹å¯¹è¯ï¼Œé‡ç‚¹å…³æ³¨å¯¹ç»§ç»­å¯¹è¯æœ‰å¸®åŠ©çš„ä¿¡æ¯ã€‚\n\n"
        "è¯·åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š\n"
        "1. æˆ‘ä»¬åšäº†ä»€ä¹ˆï¼ˆå·²å®Œæˆçš„ä»»åŠ¡å’Œæ“ä½œï¼‰\n"
        "2. æˆ‘ä»¬æ­£åœ¨åšä»€ä¹ˆï¼ˆå½“å‰è¿›è¡Œä¸­çš„å·¥ä½œï¼‰\n"
        "3. æˆ‘ä»¬æ­£åœ¨å¤„ç†å“ªäº›æ–‡ä»¶\n"
        "4. æ¥ä¸‹æ¥è¦åšä»€ä¹ˆï¼ˆè€ƒè™‘åˆ°æ–°ä¼šè¯æ— æ³•è®¿é—®æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼‰\n\n"
        "è¯·ä¿ç•™å…³é”®å†³ç­–ã€é‡è¦ä¸Šä¸‹æ–‡å’Œå¿…è¦çš„æŠ€æœ¯ç»†èŠ‚ã€‚\n\n"
        "å¯¹è¯å†…å®¹ï¼š\n"
        + "\n".join(conversation)
    )
```

2. **ç§»é™¤é•¿åº¦é™åˆ¶**ï¼š
```python
# åˆ é™¤æˆ–æ”¹ä¸ºé…ç½®æ§åˆ¶
# if len(summary) > 500:
#     summary = summary[:500] + "..."

summary = "".join(summary_parts).strip()

# å¦‚æœé…ç½®äº†æœ€å¤§é•¿åº¦ï¼Œæ‰é™åˆ¶
if config.compaction.summary_max_length:
    if len(summary) > config.compaction.summary_max_length:
        summary = summary[:config.compaction.summary_max_length] + "..."
```

3. **æ”¹è¿›æ‘˜è¦æ ¼å¼**ï¼ˆå¯é€‰ï¼‰ï¼š
```python
# å¯ä»¥å°è¯•ç»“æ„åŒ–è¾“å‡º
prompt_text = (
    "è¯·ç”¨ä»¥ä¸‹æ ¼å¼æ€»ç»“å¯¹è¯ï¼š\n\n"
    "## å·²å®Œæˆçš„å·¥ä½œ\n"
    "[æ€»ç»“å·²å®Œæˆçš„ä»»åŠ¡]\n\n"
    "## å½“å‰çŠ¶æ€\n"
    "[æ€»ç»“å½“å‰è¿›è¡Œçš„å·¥ä½œå’Œæ–‡ä»¶]\n\n"
    "## ä¸‹ä¸€æ­¥è®¡åˆ’\n"
    "[æ€»ç»“æ¥ä¸‹æ¥è¦åšçš„äº‹æƒ…]\n\n"
    "å¯¹è¯å†…å®¹ï¼š\n"
    + "\n".join(conversation)
)
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- æ‘˜è¦è´¨é‡æå‡
- æ— é•¿åº¦é™åˆ¶æ—¶å®Œæ•´è¾“å‡º
- æœ‰é•¿åº¦é™åˆ¶æ—¶æ­£ç¡®æˆªæ–­
- é”™è¯¯å¤„ç†æ­£å¸¸

**é¢„è®¡å·¥ä½œé‡**ï¼š1-2å°æ—¶

---

## é˜¶æ®µäºŒï¼šç²¾ç¡®åº¦æå‡ï¼ˆP1ï¼‰

### ä»»åŠ¡ 2.1ï¼šæ”¹è¿›è§¦å‘æœºåˆ¶ â­â­â­

**ç›®æ ‡**ï¼šæ›´ç²¾ç¡®çš„è§¦å‘æ—¶æœºï¼ŒåŸºäºå®é™…tokenä½¿ç”¨

**å®ç°æ­¥éª¤**ï¼š

1. **æ·»åŠ tokenä½¿ç”¨è¿½è¸ª**ï¼ˆ`agent.py`ï¼‰ï¼š
```python
# åœ¨ agent_loop æˆ– _call_llm ä¸­è¿½è¸ªå®é™…tokenä½¿ç”¨
# ä» LLM å“åº”ä¸­è·å–å®é™…tokenæ•°

async def _call_llm(...):
    # ... è°ƒç”¨LLM ...
    
    # è·å–å®é™…tokenä½¿ç”¨ï¼ˆå¦‚æœLLMå®¢æˆ·ç«¯æ”¯æŒï¼‰
    actual_tokens = get_token_usage()  # å‡è®¾å·²æœ‰æ­¤å‡½æ•°
    if actual_tokens:
        # æ›´æ–°æ¶ˆæ¯çš„tokenä¿¡æ¯
        assistant_msg.metadata["tokens"] = {
            "input": actual_tokens.get("input", 0),
            "output": actual_tokens.get("output", 0),
            "total": actual_tokens.get("total", 0),
        }
```

2. **æ”¹è¿›è§¦å‘é€»è¾‘**ï¼ˆ`agent.py`ï¼‰ï¼š
```python
async def _call_llm(...):
    # æ–¹æ¡ˆAï¼šæ¯æ¬¡è°ƒç”¨åæ£€æŸ¥ï¼ˆæ›´ç²¾ç¡®ï¼‰
    if step > 0:
        # è®¡ç®—ç´¯è®¡token
        total_tokens = sum(
            msg.metadata.get("tokens", {}).get("total", 0) 
            for msg in messages
        )
        # åŠ ä¸Šå½“å‰ä¼°ç®—
        current_estimate = estimate_session_tokens(messages)
        
        limit = config.max_tokens - config.compaction.reserved_tokens
        if total_tokens > limit * 0.8 or current_estimate > limit:
            # æ¥è¿‘æˆ–è¶…è¿‡é™åˆ¶ï¼Œè§¦å‘å‹ç¼©
            logger.info(f"Token usage high ({total_tokens}/{limit}), compacting...")
            try:
                messages_to_use = await compact_messages(
                    messages, config, limit, session_id
                )
            except Exception as e:
                logger.warning(f"Compaction failed: {e}")
                messages_to_use = messages
    else:
        messages_to_use = messages
```

3. **æ·»åŠ æº¢å‡ºæ£€æµ‹å‡½æ•°**ï¼ˆ`compaction.py`ï¼‰ï¼š
```python
def is_overflow(
    messages: list[Message],
    config: Config,
    model_limit: int | None = None
) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦æº¢å‡ºcontexté™åˆ¶
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        config: é…ç½®
        model_limit: æ¨¡å‹é™åˆ¶ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨config.max_tokensï¼‰
    
    Returns:
        æ˜¯å¦æº¢å‡º
    """
    limit = (model_limit or config.max_tokens) - config.compaction.reserved_tokens
    
    # ä¼˜å…ˆä½¿ç”¨å®é™…tokenæ•°
    total_actual = sum(
        msg.metadata.get("tokens", {}).get("total", 0)
        for msg in messages
    )
    
    if total_actual > 0:
        return total_actual > limit
    
    # å›é€€åˆ°ä¼°ç®—
    estimated = estimate_session_tokens(messages)
    return estimated > limit
```

4. **æ›´æ–°è°ƒç”¨ç‚¹**ï¼š
```python
# åœ¨ _call_llm ä¸­ä½¿ç”¨
if step > 0 and is_overflow(messages, config):
    messages_to_use = await compact_messages(...)
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- åŸºäºå®é™…tokenè§¦å‘
- ä¼°ç®—å›é€€æ­£å¸¸
- é˜ˆå€¼è®¾ç½®åˆç†
- ä¸ä¼šè¿‡æ—©æˆ–è¿‡æ™šè§¦å‘

**é¢„è®¡å·¥ä½œé‡**ï¼š3-4å°æ—¶

---

### ä»»åŠ¡ 2.2ï¼šTokenä¼°ç®—æ”¹è¿› â­â­

**ç›®æ ‡**ï¼šæé«˜tokenä¼°ç®—å‡†ç¡®æ€§

**å®ç°æ­¥éª¤**ï¼š

1. **æ·»åŠ tiktokenæ”¯æŒ**ï¼ˆå¯é€‰ï¼Œå¦‚æœå¯ç”¨ï¼‰ï¼š
```python
# compaction.py
try:
    import tiktoken
    _has_tiktoken = True
except ImportError:
    _has_tiktoken = False
    logger.debug("tiktoken not available, using character-based estimation")

def estimate_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
    """ä¼°ç®—tokenæ•°ï¼Œä¼˜å…ˆä½¿ç”¨tiktoken"""
    if not text:
        return 0
    
    if _has_tiktoken:
        try:
            encoding = tiktoken.encoding_for_model(model)
            return len(encoding.encode(text))
        except Exception:
            # å›é€€åˆ°å­—ç¬¦ä¼°ç®—
            pass
    
    # å­—ç¬¦ä¼°ç®—ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    # ä¸­æ–‡å­—ç¬¦é€šå¸¸1å­—ç¬¦=1tokenï¼Œè‹±æ–‡4å­—ç¬¦=1token
    chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
    other_chars = len(text) - chinese_chars
    return chinese_chars + int(other_chars * 0.25) + 1
```

2. **æ”¹è¿›æ¶ˆæ¯tokenä¼°ç®—**ï¼š
```python
def estimate_message_tokens(message: Message, model: str = "gpt-3.5-turbo") -> int:
    """ä¼°ç®—æ¶ˆæ¯tokenæ•°"""
    total = 0
    for part in message.parts:
        if isinstance(part, TextPart):
            total += estimate_tokens(part.text, model)
        elif isinstance(part, ToolPart):
            # å·¥å…·è°ƒç”¨ï¼šåç§° + å‚æ•° + è¾“å‡º
            total += 20  # åŸºç¡€å¼€é”€
            if hasattr(part, "input"):
                import json
                total += estimate_tokens(json.dumps(part.input), model)
            if hasattr(part, "output"):
                total += estimate_tokens(part.output, model)
    
    # æ¶ˆæ¯å¼€é”€ï¼šrole + æ ¼å¼
    total += 10
    return total
```

3. **ä»é…ç½®è·å–æ¨¡å‹å**ï¼š
```python
def estimate_session_tokens(
    messages: list[Message],
    model: str | None = None
) -> int:
    """ä¼°ç®—ä¼šè¯tokenæ•°"""
    model = model or "gpt-3.5-turbo"  # é»˜è®¤å€¼
    return sum(estimate_message_tokens(m, model) for m in messages)

# åœ¨ compact_messages ä¸­ä½¿ç”¨
async def compact_messages(..., config: Config, ...):
    # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
    model_name = config.model  # æˆ–ä»configè·å–
    current_tokens = estimate_session_tokens(messages, model_name)
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- tiktokenå¯ç”¨æ—¶ä½¿ç”¨
- å›é€€æœºåˆ¶æ­£å¸¸
- ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬ä¼°ç®—å‡†ç¡®
- ä¸APIå®é™…tokenæ•°æ¥è¿‘

**é¢„è®¡å·¥ä½œé‡**ï¼š4-6å°æ—¶ï¼ˆåŒ…å«tiktokené›†æˆå’Œæµ‹è¯•ï¼‰

---

## é˜¶æ®µä¸‰ï¼šé«˜çº§åŠŸèƒ½ï¼ˆP2ï¼‰

### ä»»åŠ¡ 3.1ï¼šå·¥å…·è¾“å‡ºä¿®å‰ª â­â­â­

**ç›®æ ‡**ï¼šé€‰æ‹©æ€§ä¿®å‰ªæ—§å·¥å…·è¾“å‡ºï¼Œç±»ä¼¼opencodeçš„pruneåŠŸèƒ½

**å®ç°æ­¥éª¤**ï¼š

1. **æ·»åŠ ä¿®å‰ªå‡½æ•°**ï¼ˆ`compaction.py`ï¼‰ï¼š
```python
# é…ç½®å¸¸é‡
PRUNE_PROTECT_TOKENS = 40_000  # ä¿æŠ¤æœ€è¿‘N tokensçš„å·¥å…·è¾“å‡º
PRUNE_MINIMUM_TOKENS = 20_000  # æœ€å°ä¿®å‰ªé‡
PRUNE_PROTECTED_TOOLS = []  # å—ä¿æŠ¤çš„å·¥å…·åˆ—è¡¨ï¼ˆå¯é…ç½®ï¼‰

async def prune_tool_outputs(
    messages: list[Message],
    session_id: str,
    config: Config
) -> int:
    """
    ä¿®å‰ªæ—§å·¥å…·è¾“å‡ºï¼Œä¿ç•™æœ€è¿‘çš„é‡è¦è¾“å‡º
    
    Returns:
        ä¿®å‰ªçš„tokenæ•°
    """
    if not config.compaction.enabled:
        return 0
    
    storage = get_storage()
    total_tokens = 0
    pruned_tokens = 0
    to_prune = []
    turns = 0
    
    # ä»åå¾€å‰éå†
    for msg in reversed(messages):
        if msg.role == "user":
            turns += 1
        if turns < 2:  # ä¿æŠ¤æœ€è¿‘2è½®
            continue
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å‹ç¼©æ ‡è®°
        if msg.metadata.get("compaction"):
            break
        
        # æ£€æŸ¥å·¥å…·è¾“å‡º
        for part in msg.parts:
            if isinstance(part, ToolPart):
                if part.status == "completed" and part.output:
                    # æ£€æŸ¥æ˜¯å¦å—ä¿æŠ¤
                    if part.tool in PRUNE_PROTECTED_TOOLS:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ä¿®å‰ª
                    if part.metadata.get("pruned"):
                        break
                    
                    # ä¼°ç®—token
                    tokens = estimate_tokens(part.output)
                    total_tokens += tokens
                    
                    if total_tokens > PRUNE_PROTECT_TOKENS:
                        pruned_tokens += tokens
                        to_prune.append((msg, part))
    
    # å¦‚æœä¿®å‰ªé‡è¶³å¤Ÿï¼Œæ‰§è¡Œä¿®å‰ª
    if pruned_tokens > PRUNE_MINIMUM_TOKENS:
        for msg, part in to_prune:
            # æ ‡è®°ä¸ºå·²ä¿®å‰ªï¼Œæ¸…ç©ºè¾“å‡º
            if not hasattr(part, "metadata"):
                part.metadata = {}
            part.metadata["pruned"] = True
            part.metadata["pruned_at"] = time.time()
            original_output = part.output
            part.output = "[Output pruned to save tokens]"
            
            # ä¿å­˜æ›´æ–°
            storage.save_message(session_id, msg)
            logger.debug(f"Pruned tool output: {part.tool} ({len(original_output)} chars)")
        
        logger.info(f"Pruned {pruned_tokens} tokens from {len(to_prune)} tool outputs")
        return pruned_tokens
    
    return 0
```

2. **åœ¨å‹ç¼©åè°ƒç”¨**ï¼ˆ`agent.py`ï¼‰ï¼š
```python
# åœ¨å‹ç¼©åï¼Œå°è¯•ä¿®å‰ª
if messages_to_use != messages:
    # å‹ç¼©å·²å®Œæˆï¼Œå°è¯•ä¿®å‰ªå·¥å…·è¾“å‡º
    await prune_tool_outputs(messages_to_use, session_id, config)
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- ä¿æŠ¤æœ€è¿‘2è½®
- æ­£ç¡®ä¿®å‰ªæ—§å·¥å…·è¾“å‡º
- å—ä¿æŠ¤å·¥å…·ä¸è¢«ä¿®å‰ª
- ä¿®å‰ªé‡è¾¾åˆ°é˜ˆå€¼æ‰æ‰§è¡Œ

**é¢„è®¡å·¥ä½œé‡**ï¼š6-8å°æ—¶

---

### ä»»åŠ¡ 3.2ï¼šæ‰‹åŠ¨è§¦å‘å‹ç¼© â­

**ç›®æ ‡**ï¼šæ·»åŠ CLIå‘½ä»¤æ‰‹åŠ¨è§¦å‘å‹ç¼©

**å®ç°æ­¥éª¤**ï¼š

1. **æ·»åŠ CLIå‘½ä»¤**ï¼ˆ`cli.py` æˆ–æ–°å»º `cli/commands/compact.py`ï¼‰ï¼š
```python
class CompactCommand(BaseCommand):
    """æ‰‹åŠ¨å‹ç¼©ä¼šè¯å†å²"""
    
    def setup(self, parser):
        parser.add_argument("session_id", help="ä¼šè¯ID")
        parser.add_argument(
            "--force",
            action="store_true",
            help="å¼ºåˆ¶å‹ç¼©ï¼Œå³ä½¿æœªè¶…è¿‡é™åˆ¶"
        )
    
    async def run(self, args):
        session_id = args.session_id
        config = Config.from_env()
        
        # è·å–ä¼šè¯æ¶ˆæ¯
        messages = get_session_messages(session_id)
        if not messages:
            print(f"Session {session_id} has no messages")
            return 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
        if not args.force:
            limit = config.max_tokens - config.compaction.reserved_tokens
            current = estimate_session_tokens(messages)
            if current <= limit:
                print(f"Session size ({current} tokens) within limit ({limit}), no compaction needed")
                print("Use --force to compact anyway")
                return 0
        
        # æ‰§è¡Œå‹ç¼©
        print(f"Compacting session {session_id}...")
        try:
            compacted = await compact_messages(
                messages, config, session_id=session_id
            )
            
            # æ›´æ–°ä¼šè¯æ¶ˆæ¯
            storage = get_storage()
            session = storage.load_full_session(session_id)
            if session:
                session.messages = compacted
                storage.save_full_session(session)
            
            print(f"Compaction completed: {len(messages)} -> {len(compacted)} messages")
            return 0
        except Exception as e:
            print(f"Compaction failed: {e}")
            return 1
```

2. **æ³¨å†Œå‘½ä»¤**ï¼š
```python
# åœ¨ cli.py çš„ main å‡½æ•°ä¸­
subparsers.add_parser("compact", parents=[...]).set_defaults(
    handler=CompactCommand().run
)
```

**æµ‹è¯•è¦ç‚¹**ï¼š
- å‘½ä»¤æ­£ç¡®æ‰§è¡Œ
- å¼ºåˆ¶æ¨¡å¼å·¥ä½œ
- é”™è¯¯å¤„ç†æ­£å¸¸
- æ¶ˆæ¯æ­£ç¡®æ›´æ–°

**é¢„è®¡å·¥ä½œé‡**ï¼š1-2å°æ—¶

---

## å››ã€å®æ–½æ—¶é—´è¡¨

### ç¬¬ä¸€å‘¨ï¼šé˜¶æ®µä¸€ï¼ˆå…³é”®ä¿®å¤ï¼‰

**Day 1-2**ï¼šä»»åŠ¡1.1 - ä¿å­˜å‹ç¼©å†å²
- æ‰©å±•Messageç±»
- ä¿®æ”¹å‹ç¼©å‡½æ•°
- æ·»åŠ æŸ¥è¯¢å‡½æ•°
- ç¼–å†™æµ‹è¯•

**Day 3**ï¼šä»»åŠ¡1.2 - é…ç½®åŒ–å‚æ•°
- æ‰©å±•Configç±»
- æ›´æ–°å‹ç¼©é€»è¾‘
- æ›´æ–°é…ç½®æ–‡ä»¶
- æµ‹è¯•é…ç½®åŠ è½½

**Day 4**ï¼šä»»åŠ¡1.3 - æ”¹è¿›æ‘˜è¦è´¨é‡
- æ”¹è¿›prompt
- ç§»é™¤ç¡¬é™åˆ¶
- æµ‹è¯•æ‘˜è¦è´¨é‡

**Day 5**ï¼šé›†æˆæµ‹è¯•å’Œæ–‡æ¡£
- ç«¯åˆ°ç«¯æµ‹è¯•
- æ›´æ–°æ–‡æ¡£
- ä»£ç å®¡æŸ¥

### ç¬¬äºŒå‘¨ï¼šé˜¶æ®µäºŒï¼ˆç²¾ç¡®åº¦æå‡ï¼‰

**Day 1-2**ï¼šä»»åŠ¡2.1 - æ”¹è¿›è§¦å‘æœºåˆ¶
- æ·»åŠ tokenè¿½è¸ª
- æ”¹è¿›è§¦å‘é€»è¾‘
- æµ‹è¯•è§¦å‘æ—¶æœº

**Day 3-4**ï¼šä»»åŠ¡2.2 - Tokenä¼°ç®—æ”¹è¿›
- é›†æˆtiktokenï¼ˆå¯é€‰ï¼‰
- æ”¹è¿›ä¼°ç®—ç®—æ³•
- æµ‹è¯•å‡†ç¡®æ€§

**Day 5**ï¼šä¼˜åŒ–å’Œæµ‹è¯•
- æ€§èƒ½æµ‹è¯•
- å‡†ç¡®æ€§éªŒè¯
- æ–‡æ¡£æ›´æ–°

### ç¬¬ä¸‰å‘¨ï¼šé˜¶æ®µä¸‰ï¼ˆé«˜çº§åŠŸèƒ½ï¼Œå¯é€‰ï¼‰

**Day 1-3**ï¼šä»»åŠ¡3.1 - å·¥å…·è¾“å‡ºä¿®å‰ª
- å®ç°ä¿®å‰ªé€»è¾‘
- é›†æˆåˆ°å‹ç¼©æµç¨‹
- æµ‹è¯•ä¿®å‰ªæ•ˆæœ

**Day 4**ï¼šä»»åŠ¡3.2 - æ‰‹åŠ¨è§¦å‘
- å®ç°CLIå‘½ä»¤
- æµ‹è¯•å‘½ä»¤åŠŸèƒ½

**Day 5**ï¼šæœ€ç»ˆæµ‹è¯•å’Œæ–‡æ¡£
- å®Œæ•´åŠŸèƒ½æµ‹è¯•
- æ€§èƒ½è¯„ä¼°
- æ–‡æ¡£å®Œå–„

---

## äº”ã€é£é™©è¯„ä¼°ä¸ç¼“è§£

### 5.1 æŠ€æœ¯é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| æ¶ˆæ¯å…ƒæ•°æ®ä¸å…¼å®¹ | é«˜ | ä½ | å‘åå…¼å®¹è®¾è®¡ï¼Œæ—§æ¶ˆæ¯æ— metadataæ—¶ä½¿ç”¨é»˜è®¤å€¼ |
| é…ç½®åŠ è½½å¤±è´¥ | ä¸­ | ä½ | æä¾›é»˜è®¤å€¼ï¼Œä¼˜é›…é™çº§ |
| Tokenä¼°ç®—è¯¯å·®å¤§ | ä¸­ | ä¸­ | ä½¿ç”¨å®é™…tokenä¼˜å…ˆï¼Œä¼°ç®—ä½œä¸ºå›é€€ |
| å‹ç¼©åæ€§èƒ½ä¸‹é™ | ä½ | ä½ | å‹ç¼©æ˜¯å¼‚æ­¥æ“ä½œï¼Œä¸å½±å“ä¸»æµç¨‹ |

### 5.2 æ•°æ®é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| å‹ç¼©åæ•°æ®ä¸¢å¤± | æé«˜ | ä½ | ä¿ç•™åŸå§‹æ¶ˆæ¯ï¼Œåªæ·»åŠ æ ‡è®° |
| å…ƒæ•°æ®æŸå | ä¸­ | ä½ | ä½¿ç”¨JSONæ ¼å¼ï¼ŒéªŒè¯æ•°æ®å®Œæ•´æ€§ |
| å­˜å‚¨ç©ºé—´å¢åŠ  | ä½ | ä¸­ | å¯é€‰ï¼šå‹ç¼©åå½’æ¡£æ—§æ¶ˆæ¯ |

### 5.3 å®æ–½é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| å¼€å‘æ—¶é—´è¶…æœŸ | ä¸­ | ä¸­ | åˆ†é˜¶æ®µå®æ–½ï¼Œä¼˜å…ˆå…³é”®åŠŸèƒ½ |
| æµ‹è¯•ä¸å……åˆ† | é«˜ | ä¸­ | æ¯ä¸ªä»»åŠ¡å®Œæˆåç«‹å³æµ‹è¯• |
| å‘åå…¼å®¹é—®é¢˜ | é«˜ | ä½ | ä¿æŒAPIå…¼å®¹ï¼Œæ·»åŠ æ–°å­—æ®µæ—¶ä½¿ç”¨é»˜è®¤å€¼ |

---

## å…­ã€æˆåŠŸæŒ‡æ ‡

### 6.1 åŠŸèƒ½æŒ‡æ ‡

- âœ… å‹ç¼©ååŸå§‹æ¶ˆæ¯100%ä¿ç•™
- âœ… å¯ä»¥æŸ¥è¯¢æ‰€æœ‰å‹ç¼©å†å²
- âœ… é…ç½®å‚æ•°100%å¯é…ç½®
- âœ… æ‘˜è¦è´¨é‡æå‡ï¼ˆäººå·¥è¯„ä¼°ï¼‰
- âœ… Tokenä¼°ç®—è¯¯å·® < 20%ï¼ˆä¸APIå®é™…å€¼å¯¹æ¯”ï¼‰

### 6.2 æ€§èƒ½æŒ‡æ ‡

- âœ… å‹ç¼©æ“ä½œä¸å½±å“ä¸»æµç¨‹æ€§èƒ½
- âœ… å‹ç¼©åtokenå‡å°‘ > 50%
- âœ… è§¦å‘æ—¶æœºå‡†ç¡®ï¼ˆä¸æ—©ä¸æ™šï¼‰

### 6.3 è´¨é‡æŒ‡æ ‡

- âœ… æ‰€æœ‰æ–°åŠŸèƒ½æœ‰å•å…ƒæµ‹è¯•
- âœ… é›†æˆæµ‹è¯•è¦†ç›–ä¸»è¦åœºæ™¯
- âœ… ä»£ç è¦†ç›–ç‡ > 80%
- âœ… æ–‡æ¡£å®Œæ•´æ›´æ–°

---

## ä¸ƒã€åç»­ä¼˜åŒ–æ–¹å‘

### 7.1 é«˜çº§åŠŸèƒ½ï¼ˆæœªæ¥è€ƒè™‘ï¼‰

1. **é‡è¦æ€§è¯„ä¼°**
   - åŸºäºæ¶ˆæ¯é‡è¦æ€§é€‰æ‹©ä¿ç•™/å‹ç¼©
   - ä½¿ç”¨embeddingè®¡ç®—ç›¸ä¼¼åº¦
   - ä¿ç•™å…³é”®å†³ç­–ç‚¹

2. **å¢é‡å‹ç¼©**
   - ä¸æ€»æ˜¯å…¨é‡å‹ç¼©
   - åªå‹ç¼©æœ€æ—§çš„éƒ¨åˆ†
   - ä¿ç•™æ›´å¤šä¸­é—´å†å²

3. **å‹ç¼©ç­–ç•¥é€‰æ‹©**
   - æ ¹æ®ä¼šè¯ç±»å‹é€‰æ‹©ç­–ç•¥
   - ä»£ç ä¼šè¯ vs å¯¹è¯ä¼šè¯
   - è‡ªé€‚åº”å‚æ•°è°ƒæ•´

4. **äº‹ä»¶ç³»ç»Ÿ**
   - å‘å¸ƒå‹ç¼©äº‹ä»¶
   - å…è®¸æ’ä»¶ç›‘å¬
   - æ”¯æŒè‡ªå®šä¹‰å‹ç¼©é€»è¾‘

### 7.2 æ€§èƒ½ä¼˜åŒ–

1. **å¼‚æ­¥å‹ç¼©**
   - åå°å‹ç¼©
   - ä¸é˜»å¡ä¸»æµç¨‹
   - æ¸è¿›å¼å‹ç¼©

2. **ç¼“å­˜ä¼˜åŒ–**
   - ç¼“å­˜tokenä¼°ç®—ç»“æœ
   - ç¼“å­˜å‹ç¼©å†å²æŸ¥è¯¢
   - å‡å°‘é‡å¤è®¡ç®—

3. **å­˜å‚¨ä¼˜åŒ–**
   - å‹ç¼©åå½’æ¡£æ—§æ¶ˆæ¯
   - å¯é€‰ï¼šåˆ é™¤å·²å‹ç¼©æ¶ˆæ¯ï¼ˆç”¨æˆ·ç¡®è®¤ï¼‰
   - å‹ç¼©å­˜å‚¨æ ¼å¼

---

## å…«ã€æ€»ç»“

æœ¬ä¼˜åŒ–è®¡åˆ’é‡‡ç”¨**æ¸è¿›å¼æ”¹è¿›**ç­–ç•¥ï¼Œä¼˜å…ˆè§£å†³æœ€å…³é”®çš„é—®é¢˜ï¼ˆå†å²ä¸¢å¤±ï¼‰ï¼Œç„¶åé€æ­¥æå‡ç²¾ç¡®åº¦å’Œç”¨æˆ·ä½“éªŒã€‚ä¸‰ä¸ªé˜¶æ®µçš„è®¾è®¡ç¡®ä¿äº†ï¼š

1. **å¿«é€Ÿè§æ•ˆ**ï¼šé˜¶æ®µä¸€è§£å†³æ ¸å¿ƒé—®é¢˜ï¼Œç«‹å³å¸¦æ¥ä»·å€¼
2. **é£é™©å¯æ§**ï¼šæ¯ä¸ªé˜¶æ®µç‹¬ç«‹ï¼Œå¯ä»¥éšæ—¶åœæ­¢
3. **å‘åå…¼å®¹**ï¼šæ‰€æœ‰æ”¹åŠ¨ä¿æŒAPIå…¼å®¹
4. **æ˜“äºæµ‹è¯•**ï¼šæ¯ä¸ªä»»åŠ¡éƒ½æœ‰æ˜ç¡®çš„æµ‹è¯•è¦ç‚¹

**å»ºè®®**ï¼šç«‹å³å¼€å§‹é˜¶æ®µä¸€çš„å®æ–½ï¼Œé¢„è®¡ä¸€å‘¨å†…å¯ä»¥å®Œæˆå…³é”®ä¿®å¤ï¼Œæ˜¾è‘—æå‡å‹ç¼©åŠŸèƒ½çš„å¯é æ€§å’Œå¯ç”¨æ€§ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼š1.0  
**åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-27  
**æœ€åæ›´æ–°**ï¼š2025-01-27
